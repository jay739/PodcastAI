{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bjIcBir-nB5",
        "outputId": "7d353cec-b6f7-4e77-d221-0c92c11399d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PDF Processing Completed Successfully for: w27392 (1).pdf\n",
            "Total chunks returned: 53\n",
            "============================================================\n",
            "\n",
            "--- First 3 Chunks (Returned Value Sample) ---\n",
            "\n",
            "Chunk 1 (length: 1272 chars):\n",
            "NBER WORKING PAPER SERIES THE IMPACT OF COVID-19 ON STUDENT EXPERIENCES AND EXPECTATIONS: EVIDENCE FROM A SURVEY Esteban M. Aucejo Jacob F. French Maria Paola Ugalde Araya Basit Zafar Working Paper 27...\n",
            "\n",
            "Chunk 2 (length: 1435 chars):\n",
            "f COVID-19 on Student Experiences and Expectations: Evidence from a Survey Esteban M. Aucejo, Jacob F. French, Maria Paola Ugalde Araya, and Basit Zafar NBER Working Paper No. 27392 June 2020 JEL No. ...\n",
            "\n",
            "Chunk 3 (length: 1434 chars):\n",
            "ally by socioeconomic factors and constitute key mediators in explaining the large (and heterogeneous) effects of the pandemic. Esteban M. Aucejo Department of Economics Arizona State University P.O. ...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "from pypdf import PdfReader\n",
        "import re\n",
        "import random\n",
        "from typing import List, Dict, Tuple, Any, Optional\n",
        "from datetime import datetime\n",
        "import traceback\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
        "\n",
        "# --- Function Definitions (get_pdf_file, extract_text_from_pdf, chunk_text, preprocess_text, extract_sections) ---\n",
        "# These functions remain the same as in the previous version.\n",
        "# ... (Keep the exact code for these 5 functions here) ...\n",
        "def get_pdf_file(pdf_folder: str, mode: str = \"latest\") -> str:\n",
        "    \"\"\"\n",
        "    Get PDF file path based on specified mode.\n",
        "\n",
        "    Args:\n",
        "        pdf_folder: Directory containing PDF files\n",
        "        mode: Selection mode - \"latest\", \"random\", or \"interactive\"\n",
        "\n",
        "    Returns:\n",
        "        Path to selected PDF file\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the folder doesn't exist (after attempting creation)\n",
        "                         or if no PDF files are found in the folder.\n",
        "        ValueError: If an invalid mode is provided.\n",
        "    \"\"\"\n",
        "    # Ensure folder exists\n",
        "    if not os.path.exists(pdf_folder):\n",
        "        try:\n",
        "            os.makedirs(pdf_folder, exist_ok=True)\n",
        "            logging.warning(f\"PDF folder '{pdf_folder}' did not exist and was created.\")\n",
        "            raise FileNotFoundError(f\"PDF folder '{pdf_folder}' was created, but no PDFs found.\")\n",
        "        except OSError as e:\n",
        "            logging.error(f\"Failed to create PDF folder '{pdf_folder}': {e}\")\n",
        "            raise FileNotFoundError(f\"PDF folder '{pdf_folder}' does not exist and could not be created.\")\n",
        "\n",
        "    # Get list of PDF files\n",
        "    try:\n",
        "        pdf_files = [f for f in os.listdir(pdf_folder) if f.lower().endswith('.pdf') and os.path.isfile(os.path.join(pdf_folder, f))]\n",
        "    except OSError as e:\n",
        "        logging.error(f\"Error listing files in folder '{pdf_folder}': {e}\")\n",
        "        raise FileNotFoundError(f\"Could not access files in the PDF folder '{pdf_folder}'.\")\n",
        "\n",
        "\n",
        "    if not pdf_files:\n",
        "        logging.warning(f\"No PDF files found in folder: {pdf_folder}\")\n",
        "        raise FileNotFoundError(f\"No PDF files found in {pdf_folder}\")\n",
        "\n",
        "    logging.info(f\"Found {len(pdf_files)} PDF file(s) in '{pdf_folder}'.\")\n",
        "\n",
        "    selected_file_path = None\n",
        "\n",
        "    if mode == \"latest\":\n",
        "        try:\n",
        "            latest_file = max(pdf_files, key=lambda f: os.path.getmtime(os.path.join(pdf_folder, f)))\n",
        "            selected_file_path = os.path.join(pdf_folder, latest_file)\n",
        "            logging.info(f\"Selected latest PDF: {latest_file}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error determining latest file: {e}\")\n",
        "            raise\n",
        "\n",
        "    elif mode == \"random\":\n",
        "        random_file = random.choice(pdf_files)\n",
        "        selected_file_path = os.path.join(pdf_folder, random_file)\n",
        "        logging.info(f\"Selected random PDF: {random_file}\")\n",
        "\n",
        "    elif mode == \"interactive\":\n",
        "        print(\"\\nAvailable PDF files:\")\n",
        "        for i, file in enumerate(pdf_files):\n",
        "            print(f\"{i+1}. {file}\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                choice_str = input(f\"\\nSelect PDF file number (1-{len(pdf_files)}): \")\n",
        "                choice = int(choice_str)\n",
        "                if 1 <= choice <= len(pdf_files):\n",
        "                    selected_file = pdf_files[choice-1]\n",
        "                    selected_file_path = os.path.join(pdf_folder, selected_file)\n",
        "                    logging.info(f\"User selected PDF: {selected_file}\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"Invalid choice. Please enter a number between 1 and {len(pdf_files)}.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "            except EOFError:\n",
        "                 logging.warning(\"EOF received, exiting interactive selection.\")\n",
        "                 raise ValueError(\"Interactive selection cancelled.\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid mode: '{mode}'. Must be 'latest', 'random', or 'interactive'\")\n",
        "\n",
        "    if selected_file_path is None:\n",
        "         raise RuntimeError(\"Failed to select a PDF file.\")\n",
        "\n",
        "    return selected_file_path\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str) -> Tuple[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Extract text and metadata from a PDF file using pypdf.\n",
        "\n",
        "    Args:\n",
        "        pdf_path: Path to the PDF file\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing extracted text (str) and metadata (dict)\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the PDF file does not exist or is not a file.\n",
        "        Exception: If any error occurs during PDF processing with pypdf.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if not os.path.isfile(pdf_path):\n",
        "        raise FileNotFoundError(f\"Path exists but is not a file: {pdf_path}\")\n",
        "\n",
        "    try:\n",
        "        logging.info(f\"Opening PDF: {os.path.basename(pdf_path)} using pypdf\")\n",
        "        reader = PdfReader(pdf_path)\n",
        "        metadata = reader.metadata\n",
        "        num_pages = len(reader.pages)\n",
        "\n",
        "        # Extract metadata using pypdf's metadata object\n",
        "        extracted_metadata = {\n",
        "            \"title\": getattr(metadata, 'title', os.path.basename(pdf_path)),\n",
        "            \"author\": getattr(metadata, 'author', \"Unknown\"),\n",
        "            \"subject\": getattr(metadata, 'subject', \"\"),\n",
        "            \"creator\": getattr(metadata, 'creator', \"\"),\n",
        "            \"producer\": getattr(metadata, 'producer', \"\"),\n",
        "            \"page_count\": num_pages,\n",
        "            \"is_encrypted\": reader.is_encrypted,\n",
        "            \"file_name\": os.path.basename(pdf_path),\n",
        "            \"file_path\": pdf_path\n",
        "        }\n",
        "\n",
        "        logging.info(f\"Extracting text from {num_pages} page(s)...\")\n",
        "        full_text = \"\"\n",
        "        for page_num, page in enumerate(reader.pages):\n",
        "            try:\n",
        "                 text = page.extract_text()\n",
        "                 if text:\n",
        "                     full_text += text + \"\\n\\n\"\n",
        "                 else:\n",
        "                      logging.warning(f\"No text extracted from page {page_num + 1}.\")\n",
        "                      full_text += f\"[Page {page_num + 1} text could not be extracted or is empty]\\n\\n\"\n",
        "            except Exception as page_error:\n",
        "                 logging.warning(f\"Could not extract text from page {page_num + 1}: {page_error}\")\n",
        "                 full_text += f\"[Page {page_num + 1} text extraction failed: {page_error}]\\n\\n\"\n",
        "\n",
        "        logging.info(f\"Successfully extracted {len(full_text)} characters from PDF.\")\n",
        "        full_text = full_text.replace('\\x00', '')\n",
        "\n",
        "        return full_text, extracted_metadata\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting text from PDF '{os.path.basename(pdf_path)}' using pypdf: {e}\")\n",
        "        logging.error(traceback.format_exc())\n",
        "        raise\n",
        "\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 150) -> List[str]:\n",
        "    \"\"\"\n",
        "    Split text into potentially overlapping chunks based on character count,\n",
        "    attempting to break at paragraphs or sentences near the target size.\n",
        "\n",
        "    Args:\n",
        "        text: The input text to chunk\n",
        "        chunk_size: Target size of each chunk in characters (approximate)\n",
        "        overlap: Number of characters to overlap between consecutive chunks\n",
        "\n",
        "    Returns:\n",
        "        List of text chunks\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        logging.warning(\"chunk_text received non-string input, returning empty list.\")\n",
        "        return []\n",
        "    if not text.strip():\n",
        "         logging.info(\"chunk_text received empty or whitespace-only text.\")\n",
        "         return []\n",
        "    if not isinstance(chunk_size, int) or chunk_size <= 0:\n",
        "         logging.warning(f\"Invalid chunk_size ({chunk_size}), using default 1000.\")\n",
        "         chunk_size = 1000\n",
        "    if not isinstance(overlap, int) or overlap < 0:\n",
        "         logging.warning(f\"Invalid overlap ({overlap}), using default 150.\")\n",
        "         overlap = 150\n",
        "    if overlap >= chunk_size:\n",
        "         logging.warning(f\"Overlap ({overlap}) >= chunk_size ({chunk_size}), reducing overlap.\")\n",
        "         overlap = max(0, chunk_size // 5)\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_length = len(text)\n",
        "\n",
        "    if text_length <= chunk_size:\n",
        "        logging.info(\"Text length is less than or equal to chunk_size, returning as single chunk.\")\n",
        "        return [text.strip()]\n",
        "\n",
        "    while start < text_length:\n",
        "        end = min(start + chunk_size, text_length)\n",
        "        actual_end = end\n",
        "\n",
        "        if end < text_length:\n",
        "            search_start = max(start, end - overlap - (chunk_size // 10))\n",
        "            search_end = end\n",
        "\n",
        "            paragraph_break = text.rfind('\\n\\n', search_start, search_end)\n",
        "            if paragraph_break != -1:\n",
        "                 actual_end = paragraph_break + 2\n",
        "            else:\n",
        "                sentence_break = -1\n",
        "                for punct in ['.', '?', '!']:\n",
        "                     break_pos = text.rfind(punct + ' ', search_start, search_end)\n",
        "                     if break_pos != -1: sentence_break = max(sentence_break, break_pos + 2)\n",
        "                     break_pos_nl = text.rfind(punct + '\\n', search_start, search_end)\n",
        "                     if break_pos_nl != -1: sentence_break = max(sentence_break, break_pos_nl + 2)\n",
        "\n",
        "                if sentence_break != -1:\n",
        "                     actual_end = sentence_break\n",
        "                else:\n",
        "                     newline_break = text.rfind('\\n', search_start, search_end)\n",
        "                     if newline_break != -1:\n",
        "                          actual_end = newline_break + 1\n",
        "\n",
        "        if actual_end <= start:\n",
        "            actual_end = end\n",
        "\n",
        "        chunk = text[start:actual_end].strip()\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        next_start = actual_end - overlap\n",
        "        if next_start <= start:\n",
        "             next_start = start + (chunk_size - overlap)\n",
        "             if next_start <= start :\n",
        "                  next_start = actual_end\n",
        "\n",
        "        start = next_start\n",
        "\n",
        "        if len(chunks) > text_length:\n",
        "             logging.error(\"Chunking loop exceeded text length, breaking.\")\n",
        "             break\n",
        "\n",
        "    logging.info(f\"Text split into {len(chunks)} chunks (size ~{chunk_size}, overlap ~{overlap})\")\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Perform basic preprocessing on extracted text.\n",
        "\n",
        "    Args:\n",
        "        text: Raw text extracted from PDF\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed text (str)\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "         logging.warning(\"preprocess_text received non-string input.\")\n",
        "         return \"\"\n",
        "\n",
        "    logging.debug(f\"Preprocessing text ({len(text)} characters)...\")\n",
        "\n",
        "    text = re.sub(r'(\\w)-\\n(\\w)', r'\\1\\2', text)\n",
        "    logging.debug(\"Applied hyphenation fix.\")\n",
        "\n",
        "    text = text.replace('\\n\\n', '<<PARAGRAPH_BREAK>>')\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.replace('<<PARAGRAPH_BREAK>>', '\\n\\n')\n",
        "    logging.debug(\"Normalized whitespace.\")\n",
        "\n",
        "    text = text.strip()\n",
        "    logging.info(f\"Preprocessing finished, final text length: {len(text)} characters.\")\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_sections(text: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Attempt to extract logical sections based on common heading patterns.\n",
        "\n",
        "    Args:\n",
        "        text: Preprocessed document text\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of section name to section content.\n",
        "        Returns {\"Full Text\": text} if no sections are identified.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "         logging.warning(\"extract_sections received empty or invalid text.\")\n",
        "         return {\"Full Text\": text or \"\"}\n",
        "\n",
        "    sections = {}\n",
        "    heading_pattern = re.compile(\n",
        "        r'^(?:(?:\\d+\\.|[IVXLCDM]+\\.|[a-zA-Z]\\))\\s*)?'\n",
        "        r'([A-Z][A-Z0-9\\s\\-]{3,}|[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)'\n",
        "        r'\\s*(?:\\n|$)',\n",
        "        re.MULTILINE\n",
        "    )\n",
        "\n",
        "    matches = list(heading_pattern.finditer(text))\n",
        "\n",
        "    if not matches:\n",
        "        logging.info(\"No distinct section headings found using the pattern.\")\n",
        "        return {\"Full Text\": text}\n",
        "\n",
        "    logging.info(f\"Found {len(matches)} potential section headings.\")\n",
        "\n",
        "    last_pos = 0\n",
        "    first_match_start = matches[0].start()\n",
        "    if first_match_start > 0:\n",
        "        preface_content = text[0:first_match_start].strip()\n",
        "        if preface_content:\n",
        "            sections[\"Preface\"] = preface_content\n",
        "            logging.debug(\"Extracted 'Preface' section.\")\n",
        "        last_pos = first_match_start\n",
        "\n",
        "    for i, match in enumerate(matches):\n",
        "        section_name = match.group(1).strip()\n",
        "        section_start = match.start()\n",
        "\n",
        "        if i + 1 < len(matches):\n",
        "            section_end = matches[i+1].start()\n",
        "        else:\n",
        "            section_end = len(text)\n",
        "\n",
        "        content_start = match.end()\n",
        "        section_content = text[content_start:section_end].strip()\n",
        "\n",
        "        if section_content:\n",
        "             if section_name in sections:\n",
        "                  logging.warning(f\"Duplicate section name '{section_name}' found. Appending count.\")\n",
        "                  count = 2\n",
        "                  new_name = f\"{section_name}_{count}\"\n",
        "                  while new_name in sections:\n",
        "                       count += 1\n",
        "                       new_name = f\"{section_name}_{count}\"\n",
        "                  section_name = new_name\n",
        "             sections[section_name] = section_content\n",
        "             logging.debug(f\"Extracted section: '{section_name}'\")\n",
        "\n",
        "    if not sections:\n",
        "         logging.warning(\"Section extraction resulted in an empty dictionary, returning full text.\")\n",
        "         return {\"Full Text\": text}\n",
        "\n",
        "    return sections\n",
        "\n",
        "\n",
        "# --- New Function to Encapsulate Processing ---\n",
        "def process_pdf(pdf_folder: str, selection_mode: str, chunk_size: int, chunk_overlap: int) -> Tuple[Optional[List[str]], Optional[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Processes a selected PDF file to extract text, metadata, and generate text chunks.\n",
        "\n",
        "    Args:\n",
        "        pdf_folder: Directory containing PDF files.\n",
        "        selection_mode: Mode for selecting PDF ('latest', 'random', 'interactive').\n",
        "        chunk_size: Target size for text chunks.\n",
        "        chunk_overlap: Overlap between text chunks.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "          - List of text chunks (List[str]) or None if an error occurs.\n",
        "          - Metadata dictionary (Dict[str, Any]) or None if an error occurs.\n",
        "    \"\"\"\n",
        "    selected_pdf_path = \"\"\n",
        "    try:\n",
        "        # Step 1: Get PDF Path\n",
        "        selected_pdf_path = get_pdf_file(pdf_folder, mode=selection_mode)\n",
        "        logging.info(f\"Selected PDF for processing: {selected_pdf_path}\")\n",
        "\n",
        "        # Step 2: Extract Text and Metadata\n",
        "        extracted_text, pdf_metadata = extract_text_from_pdf(selected_pdf_path)\n",
        "        logging.info(\"Text and metadata extracted successfully.\")\n",
        "        # Optionally print metadata here if still desired for console feedback\n",
        "        # print(\"\\n--- PDF Metadata (from pypdf) ---\")\n",
        "        # for key, value in pdf_metadata.items(): ...\n",
        "\n",
        "        # Step 3: Preprocess Text\n",
        "        preprocessed_text = preprocess_text(extracted_text)\n",
        "        logging.info(\"Text preprocessing completed.\")\n",
        "\n",
        "        # Step 4: Chunk Text\n",
        "        text_chunks = chunk_text(preprocessed_text, chunk_size=chunk_size, overlap=chunk_overlap)\n",
        "        logging.info(f\"Text chunking completed. {len(text_chunks)} chunks created.\")\n",
        "\n",
        "        # Step 5 (Optional): Extract Sections - not returned, but logged if needed\n",
        "        # document_sections = extract_sections(preprocessed_text)\n",
        "        # logging.info(f\"Section extraction attempted: {len(document_sections)} potential sections found.\")\n",
        "\n",
        "        # Return the chunks and metadata\n",
        "        return text_chunks, pdf_metadata\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        logging.error(f\"File/Folder Error during processing: {e}\")\n",
        "        print(f\"\\nERROR: {e}\")\n",
        "        return None, None # Return None on error\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"Configuration or Input Error during processing: {e}\")\n",
        "        print(f\"\\nERROR: {e}\")\n",
        "        return None, None # Return None on error\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred during processing pdf '{selected_pdf_path}': {e}\", exc_info=True)\n",
        "        print(f\"\\nUNEXPECTED ERROR processing {os.path.basename(selected_pdf_path)}: {e}\")\n",
        "        return None, None # Return None on error\n",
        "\n",
        "\n",
        "# --- Main execution block ---\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Script execution started.\")\n",
        "\n",
        "    # <<< --- CONFIGURATION --- >>>\n",
        "    PDF_FOLDER = \"my_pdfs\"  # IMPORTANT: Change this to the path of your folder\n",
        "    SELECTION_MODE = \"random\" # \"latest\", \"random\", or \"interactive\"\n",
        "    CHUNK_SIZE = 1500        # Adjusted chunk size\n",
        "    CHUNK_OVERLAP = 200\n",
        "    # <<< --- END CONFIGURATION --- >>>\n",
        "\n",
        "    # Call the processing function\n",
        "    all_chunks, metadata = process_pdf(\n",
        "        pdf_folder=PDF_FOLDER,\n",
        "        selection_mode=SELECTION_MODE,\n",
        "        chunk_size=CHUNK_SIZE,\n",
        "        chunk_overlap=CHUNK_OVERLAP\n",
        "    )\n",
        "\n",
        "    # Check the results and print confirmation/output\n",
        "    if all_chunks is not None:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"PDF Processing Completed Successfully for: {metadata.get('file_name', 'N/A')}\")\n",
        "        print(f\"Total chunks returned: {len(all_chunks)}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Optionally, print the first few chunks to verify the returned list\n",
        "        print(\"\\n--- First 3 Chunks (Returned Value Sample) ---\")\n",
        "        for i, chunk in enumerate(all_chunks[:3]):\n",
        "             print(f\"\\nChunk {i + 1} (length: {len(chunk)} chars):\")\n",
        "             # Print first 200 chars of each sample chunk\n",
        "             print(chunk[:200] + \"...\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # You can now use the 'all_chunks' list for further processing\n",
        "        # For example:\n",
        "        # process_chunks_further(all_chunks)\n",
        "\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"PDF Processing Failed. Check logs for details.\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "\n",
        "    logging.info(\"Script execution finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7jVVAuo-33P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}